{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_dt:\n",
    "    \n",
    "    def __init__(self, max_depth=8, min_impurity_decrease=0, min_samples=2):\n",
    "        self.max_depth = int(max_depth)\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.min_samples = int(min_samples)\n",
    "    \n",
    "    def check_purity(self,training_data):\n",
    "        label = training_data[:,-1]\n",
    "        unique_label = np.unique(label)\n",
    "        \n",
    "        if len(unique_label) == 1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def classify_data(self, training_data):\n",
    "        label_col = training_data[:,-1]\n",
    "        unique_label, count_unique_label = np.unique(label_col, return_counts = True)\n",
    "        \n",
    "        col_index = count_unique_label.argmax()\n",
    "        classification = unique_label[col_index]\n",
    "                \n",
    "        return classification\n",
    "    \n",
    "    \n",
    "    def calculate_gini(self, training_data):\n",
    "        label = training_data[:,-1]\n",
    "        _, unique_label_counts = np.unique(label, return_counts = True)\n",
    "        \n",
    "        probability = unique_label_counts / (unique_label_counts).sum()\n",
    "        gini = 0\n",
    "        gini = 1 - sum(probability ** 2)\n",
    "        \n",
    "        return gini\n",
    "        \n",
    "    \n",
    "    def calculate_overall_gini(self, data_above, data_below):\n",
    "        n = len(data_above) + len(data_below)\n",
    "        p_data_above = len(data_above) / n\n",
    "        p_data_below = len(data_below) / n\n",
    "        \n",
    "        overall_gini = (p_data_above * self.calculate_gini(data_above)+\n",
    "                    p_data_below * self.calculate_gini(data_below))\n",
    "\n",
    "        return overall_gini\n",
    "    \n",
    "    \n",
    "    def get_potential_splits(self,data):\n",
    "    \n",
    "        potential_splits = {}\n",
    "        _, n_columns = data.shape\n",
    "        for column_index in range(n_columns - 1):        # excluding the last column which is the label\n",
    "            potential_splits[column_index] = []\n",
    "            values = data[:, column_index]\n",
    "            unique_values = np.unique(values)\n",
    "\n",
    "            for index in range(len(unique_values)):\n",
    "                if index != 0:\n",
    "                    current_value = unique_values[index]\n",
    "                    previous_value = unique_values[index - 1]\n",
    "                    potential_split = (current_value + previous_value) / 2\n",
    "                \n",
    "                    potential_splits[column_index].append(potential_split)\n",
    "    \n",
    "        return potential_splits\n",
    "    \n",
    "    \n",
    "    def split_data(self, training_data, split_column, split_value):\n",
    "        split_column_values = training_data[:,split_column]\n",
    "        \n",
    "        data_below = training_data[split_column_values <= split_value]\n",
    "        data_above = training_data[split_column_values >  split_value]\n",
    "    \n",
    "        return data_below, data_above\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    def determine_best_split(self, training_data, potential_splits):\n",
    "        best_gini = 9999\n",
    "        \n",
    "        for column_index in potential_splits:\n",
    "            for value in potential_splits[column_index]:\n",
    "                data_below, data_above = self.split_data(training_data, split_column=column_index, split_value=value)\n",
    "                current_overall_gini = self.calculate_overall_gini(data_below, data_above)\n",
    "\n",
    "                if current_overall_gini <= best_gini:\n",
    "                    best_gini = current_overall_gini\n",
    "                    best_split_column = column_index\n",
    "                    best_split_value = value\n",
    "    \n",
    "        return best_split_column, best_split_value        \n",
    "        \n",
    "        \n",
    "    def treeAlgorithm(self, data_train, counter = 0):\n",
    "        # data preparations\n",
    "        if counter == 0:\n",
    "            global COLUMN_HEADERS\n",
    "            COLUMN_HEADERS = data_train.columns\n",
    "            data = data_train.values\n",
    "        else:\n",
    "            data = data_train\n",
    "            \n",
    "        # base cases\n",
    "        if (self.check_purity(data)) or (len(data) < self.min_samples) or (counter == self.max_depth):\n",
    "            classification = self.classify_data(data)\n",
    "        \n",
    "            return classification\n",
    "\n",
    "    \n",
    "        # recursive part\n",
    "        else:    \n",
    "            counter += 1\n",
    "\n",
    "            # helper functions \n",
    "            potential_splits = self.get_potential_splits(data)\n",
    "            split_column, split_value = self.determine_best_split(data, potential_splits)\n",
    "            data_below, data_above = self.split_data(data, split_column, split_value)\n",
    "\n",
    "            # instantiate sub-tree\n",
    "            feature_name = COLUMN_HEADERS[split_column]\n",
    "            question = \"{} <= {}\".format(feature_name, split_value)\n",
    "            sub_tree = {question: []}\n",
    "\n",
    "            # find answers (recursion)\n",
    "            yes_answer = self.treeAlgorithm(data_below, counter)\n",
    "            no_answer = self.treeAlgorithm(data_above, counter)\n",
    "\n",
    "            # If the answers are the same, then there is no point in asking the qestion.\n",
    "            # This could happen when the data is classified even though it is not pure\n",
    "            # yet (min_samples or max_depth base cases).\n",
    "            if yes_answer == no_answer:\n",
    "                sub_tree = yes_answer\n",
    "            else:\n",
    "                sub_tree[question].append(yes_answer)\n",
    "                sub_tree[question].append(no_answer)\n",
    "\n",
    "            return sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
